"""
Train Fire Detection CNN on Minecraft Data
Usage: python models/train_minecraft_cnn.py

Requirements:
- Collect 500-1000 training samples first
- training_data/fire_detected/ (fire images)
- training_data/no_fire/ (safe images)
"""

import os
import sys
import shutil
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import json

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

try:
    from models.fire_cnn import FireCNN
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("‚ùå Could not import FireCNN. Make sure TensorFlow is installed.")

def check_training_data():
    """Check if we have enough training data"""
    training_dir = Path("training_data")

    if not training_dir.exists():
        print("‚ùå training_data/ directory not found!")
        print("   Run the bot first to collect training data:")
        print("   python3 advanced_ai_firebot.py")
        return False, 0, 0

    fire_dir = training_dir / "fire_detected"
    no_fire_dir = training_dir / "no_fire"
    uncertain_dir = training_dir / "uncertain"

    # Count images
    fire_count = len(list(fire_dir.glob("*.jpg"))) if fire_dir.exists() else 0
    no_fire_count = len(list(no_fire_dir.glob("*.jpg"))) if no_fire_dir.exists() else 0
    uncertain_count = len(list(uncertain_dir.glob("*.jpg"))) if uncertain_dir.exists() else 0

    total = fire_count + no_fire_count

    print(f"\nüìä Training Data Analysis:")
    print(f"   üî• Fire detected: {fire_count} images")
    print(f"   ‚úÖ No fire: {no_fire_count} images")
    print(f"   ‚ùì Uncertain: {uncertain_count} images (ignored)")
    print(f"   üìÅ Total usable: {total} images")

    # Check minimum requirements
    if total < 100:
        print(f"\n‚ö†Ô∏è  WARNING: Only {total} training images")
        print("   Recommended: 500-1000+ images for good performance")
        print("   Continue anyway for testing purposes? (y/n)")
        response = input().strip().lower()
        if response != 'y':
            return False, fire_count, no_fire_count

    # Check for class imbalance
    if fire_count < 20 or no_fire_count < 20:
        print(f"\n‚ö†Ô∏è  WARNING: Class imbalance detected")
        print(f"   Fire images: {fire_count}, No fire images: {no_fire_count}")
        print("   Need at least 20 images of each class")

    return True, fire_count, no_fire_count

def prepare_training_data():
    """Split training data into train/validation sets"""
    training_dir = Path("training_data")

    # Create train/validation directories
    train_dir = Path("training_data_split/train")
    val_dir = Path("training_data_split/val")

    for dir_path in [train_dir, val_dir]:
        (dir_path / "fire_detected").mkdir(parents=True, exist_ok=True)
        (dir_path / "no_fire").mkdir(parents=True, exist_ok=True)

    # Get file lists
    fire_files = list((training_dir / "fire_detected").glob("*.jpg"))
    no_fire_files = list((training_dir / "no_fire").glob("*.jpg"))

    # Split data (80% train, 20% val)
    fire_train, fire_val = train_test_split(fire_files, test_size=0.2, random_state=42)
    no_fire_train, no_fire_val = train_test_split(no_fire_files, test_size=0.2, random_state=42)

    # Copy files
    def copy_files(file_list, target_dir):
        for file_path in file_list:
            shutil.copy2(file_path, target_dir / file_path.name)

    print("üìÇ Preparing training data split...")
    copy_files(fire_train, train_dir / "fire_detected")
    copy_files(fire_val, val_dir / "fire_detected")
    copy_files(no_fire_train, train_dir / "no_fire")
    copy_files(no_fire_val, val_dir / "no_fire")

    print(f"‚úÖ Training data split created:")
    print(f"   Train: {len(fire_train) + len(no_fire_train)} images")
    print(f"   Validation: {len(fire_val) + len(no_fire_val)} images")

    return train_dir, val_dir

def evaluate_model(model, val_dir):
    """Evaluate model performance"""
    if not TF_AVAILABLE:
        return

    print("\nüìà Evaluating model performance...")

    # Get validation data
    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    val_generator = val_datagen.flow_from_directory(
        val_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',
        shuffle=False  # Keep order for evaluation
    )

    # Get predictions
    y_pred_proba = model.model.predict(val_generator, verbose=0)
    y_pred = (y_pred_proba > 0.5).astype(int).flatten()
    y_true = val_generator.classes

    # Classification report
    print("\nüìä Classification Report:")
    print(classification_report(y_true, y_pred, target_names=['no_fire', 'fire_detected']))

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['no_fire', 'fire_detected'],
                yticklabels=['no_fire', 'fire_detected'])
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig('models/confusion_matrix.png')
    plt.show()

    return {
        'accuracy': float(np.mean(y_pred == y_true)),
        'confusion_matrix': cm.tolist(),
        'classification_report': classification_report(y_true, y_pred, target_names=['no_fire', 'fire_detected'])
    }

def plot_training_history(history):
    """Plot training curves"""
    if not history:
        return

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # Accuracy plot
    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title('Model Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()

    # Loss plot
    ax2.plot(history.history['loss'], label='Training Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title('Model Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()

    plt.tight_layout()
    plt.savefig('models/training_curves.png')
    plt.show()

def main():
    print("üî• Minecraft FireCNN Training")
    print("=" * 50)

    # Check training data
    has_data, fire_count, no_fire_count = check_training_data()
    if not has_data:
        print("\n‚ùå Insufficient training data!")
        print("\nTo collect training data:")
        print("1. Start Minecraft with a fire test world")
        print("2. Run: python3 advanced_ai_firebot.py")
        print("3. Let it collect 500+ images")
        print("4. Re-run this training script")
        return

    if not TF_AVAILABLE:
        print("\n‚ùå TensorFlow not available!")
        print("Install with: pip install tensorflow")
        return

    # Prepare data split
    train_dir, val_dir = prepare_training_data()

    # Create and train model
    print("\nüöÄ Starting training...")
    cnn = FireCNN()

    # Train model
    history = cnn.train(
        train_data=train_dir,
        val_data=val_dir,
        epochs=10,  # Start with 10, can increase
        batch_size=32
    )

    # Plot training history
    plot_training_history(history)

    # Evaluate model
    metrics = evaluate_model(cnn, val_dir)

    # Save model
    model_path = "models/fire_cnn_trained.h5"
    cnn.save_model(model_path)

    # Also save just weights (smaller file)
    weights_path = "models/fire_cnn_weights.h5"
    cnn.save_weights(weights_path)

    # Save training info
    training_info = {
        'training_date': str(Path().resolve()),
        'fire_images': fire_count,
        'no_fire_images': no_fire_count,
        'total_images': fire_count + no_fire_count,
        'model_path': model_path,
        'weights_path': weights_path,
        'input_shape': cnn.input_shape,
        'metrics': metrics
    }

    with open('models/training_info.json', 'w') as f:
        json.dump(training_info, f, indent=2)

    print(f"\n‚úÖ Training completed successfully!")
    print(f"\nüìÅ Files created:")
    print(f"   - {model_path} (Full model)")
    print(f"   - {weights_path} (Weights only)")
    print(f"   - models/training_curves.png")
    print(f"   - models/confusion_matrix.png")
    print(f"   - models/training_info.json")

    print(f"\nüéØ Model Performance:")
    if metrics:
        print(f"   Accuracy: {metrics['accuracy']:.1%}")
    print(f"   Model size: ~1MB (vs 4.7GB for LLaVA)")
    print(f"   Inference speed: <50ms (vs 2000-5000ms for LLaVA)")

    print(f"\nüöÄ Ready to integrate with FireBot!")
    print(f"   See models/integration_guide.md for next steps")

if __name__ == "__main__":
    try:
        import tensorflow as tf
    except ImportError:
        print("‚ùå TensorFlow not found. Install with:")
        print("   pip install tensorflow matplotlib seaborn scikit-learn")
        sys.exit(1)

    main()